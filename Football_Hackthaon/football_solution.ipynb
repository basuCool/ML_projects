{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __Step 1: Importing the Relevant Libraries__\n",
    "    \n",
    "* __Step 2: Data Inspection__\n",
    "    \n",
    "* __Step 3: Data Cleaning__\n",
    "    \n",
    "* __Step 4: Exploratory Data Analysis__\n",
    "    \n",
    "* __Step 5: Building Model__\n",
    "    \n",
    "* __How to Make a Submission?__\n",
    "* __Guidelines for Final Submission__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Importing the Relevant Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('always')\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Data Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"./train_1K0BDt5/train.csv\")\n",
    "test = pd.read_csv(\"./test_kuhCxHY/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20453, 800), (8774, 799))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape,test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "row_id                            0.000000\n",
       "scout_id                          0.000000\n",
       "rating_num                        0.000000\n",
       "winner                            0.000000\n",
       "team                              0.000000\n",
       "                                    ...   \n",
       "team2_defensive_derived_var_15    6.976972\n",
       "team2_offensive_derived_var_16    6.976972\n",
       "team2_defensive_derived_var_17    6.976972\n",
       "team2_offensive_derived_var_18    6.976972\n",
       "team2_offensive_derived_var_19    6.976972\n",
       "Length: 800, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ratio of null values\n",
    "train.isnull().sum()/train.shape[0] *100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "team2_other_ratio_var_32    100.0\n",
       "team2_other_raw_var_51      100.0\n",
       "team1_other_ratio_var_32    100.0\n",
       "team2_other_raw_var_40      100.0\n",
       "team2_other_raw_var_43      100.0\n",
       "                            ...  \n",
       "player_general_var_2          0.0\n",
       "player_general_var_3          0.0\n",
       "player_general_var_5          0.0\n",
       "scout_id                      0.0\n",
       "row_id                        0.0\n",
       "Length: 799, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ratio of null values\n",
    "(test.isnull().sum()/test.shape[0] *100).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __We have some columns having 100% missing values. Need to drop those columns__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical Features in Train Set: 2\n",
      "Numerical Features in Train Set: 798\n"
     ]
    }
   ],
   "source": [
    "#categorical features\n",
    "categorical = train.select_dtypes(include =[np.object])\n",
    "print(\"Categorical Features in Train Set:\",categorical.shape[1])\n",
    "\n",
    "#numerical features\n",
    "numerical= train.select_dtypes(include =[np.float64,np.int64])\n",
    "print(\"Numerical Features in Train Set:\",numerical.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical Features in Test Set: 2\n",
      "Numerical Features in Test Set: 797\n"
     ]
    }
   ],
   "source": [
    "#categorical features\n",
    "categorical_test = test.select_dtypes(include =[np.object])\n",
    "print(\"Categorical Features in Test Set:\",categorical_test.shape[1])\n",
    "\n",
    "#numerical features\n",
    "numerical_test= test.select_dtypes(include =[np.float64,np.int64])\n",
    "print(\"Numerical Features in Test Set:\",numerical_test.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why missing values treatment is required?\n",
    "Missing data in the training data set can reduce the power / fit of a model or can lead to a biased model because we have not analysed the behavior and relationship with other variables correctly. It can lead to wrong prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "row_id                               0\n",
       "scout_id                             0\n",
       "rating_num                           0\n",
       "winner                               0\n",
       "team                                 0\n",
       "                                  ... \n",
       "team2_defensive_derived_var_15    1427\n",
       "team2_offensive_derived_var_16    1427\n",
       "team2_defensive_derived_var_17    1427\n",
       "team2_offensive_derived_var_18    1427\n",
       "team2_offensive_derived_var_19    1427\n",
       "Length: 800, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "row_id                              0\n",
       "scout_id                            0\n",
       "winner                              0\n",
       "team                                1\n",
       "competitionId                       1\n",
       "                                 ... \n",
       "team2_defensive_derived_var_15    416\n",
       "team2_offensive_derived_var_16    416\n",
       "team2_defensive_derived_var_17    416\n",
       "team2_offensive_derived_var_18    416\n",
       "team2_offensive_derived_var_19    416\n",
       "Length: 799, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__3.1 Loop through the features and remove the columns which are having more than 50% missing values__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "na = (train.isna().sum()/len(train))*100\n",
    "sorted_NA = na.sort_values(ascending = False)\n",
    "null_var_names = []\n",
    "for i in range(0, len(sorted_NA)):\n",
    "    if sorted_NA[i]>25.0:\n",
    "        null_var_names.append(sorted_NA.index[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the columns with more than 50% missing values\n",
    "train_new = train.drop(columns = null_var_names)\n",
    "test_new = test.drop(columns = null_var_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_new.team.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_new[categorical.columns[0]].isna().sum(), test[categorical.columns[0]].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_new[categorical.columns[1]].isna().sum(), test[categorical.columns[1]].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert categorical values to numerical.\n",
    "# The cat variables are Ordinal data. So, it would be good to label encode them\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "for i in categorical.columns:\n",
    "    train_new[i] = encoder.fit_transform(train_new[i])\n",
    "for i in categorical_test.columns:\n",
    "    test_new[i] = encoder.fit_transform(test_new[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        1\n",
       "2        0\n",
       "3        1\n",
       "4        0\n",
       "        ..\n",
       "20448    1\n",
       "20449    1\n",
       "20450    0\n",
       "20451    0\n",
       "20452    1\n",
       "Name: team, Length: 20453, dtype: int32"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_new.team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_new.winner.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the missing values with mean of the values. Categorical variables do not have missing values\n",
    "col_new = train_new.columns\n",
    "\n",
    "#Replace the missing values with mean value\n",
    "for i in range(0, train_new.shape[1]):\n",
    "    m =train_new[col_new[i]].mean()\n",
    "    train_new[col_new[i]].fillna(m, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the missing values with mean of the values. Categorical variables do not have missing values\n",
    "col_new_test = test_new.columns\n",
    "\n",
    "#Replace the missing values with mean value\n",
    "for i in range(0, test_new.shape[1]):\n",
    "    m =test_new[col_new_test[i]].mean()\n",
    "    test_new[col_new_test[i]].fillna(m, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "row_id                            0\n",
       "scout_id                          0\n",
       "rating_num                        0\n",
       "winner                            0\n",
       "team                              0\n",
       "                                 ..\n",
       "team2_defensive_derived_var_15    0\n",
       "team2_offensive_derived_var_16    0\n",
       "team2_defensive_derived_var_17    0\n",
       "team2_offensive_derived_var_18    0\n",
       "team2_offensive_derived_var_19    0\n",
       "Length: 661, dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_new.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "row_id                            0\n",
       "scout_id                          0\n",
       "winner                            0\n",
       "team                              0\n",
       "competitionId                     0\n",
       "                                 ..\n",
       "team2_defensive_derived_var_15    0\n",
       "team2_offensive_derived_var_16    0\n",
       "team2_defensive_derived_var_17    0\n",
       "team2_offensive_derived_var_18    0\n",
       "team2_offensive_derived_var_19    0\n",
       "Length: 660, dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_new.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_new.drop(columns = ['rating_num', 'row_id'])\n",
    "y = train_new.rating_num\n",
    "X_validate = test_new.drop(columns = ['row_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20453, 659), (20453,), (8774, 659))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape, X_validate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14317, 659), (6136, 659), (14317,), (6136,))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29639795904282096\n"
     ]
    }
   ],
   "source": [
    "# Model building using lightb GBM\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "lgbm = LGBMRegressor()\n",
    "lgbm.fit(X_train,y_train)\n",
    "y_pred = lgbm.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('sample_submission_wBWLI0s.csv')\n",
    "final_predictions = lgbm.predict(X_validate)\n",
    "submission['rating_num'] = final_predictions\n",
    "#only positive predictions for the target variable\n",
    "submission['rating_num'] = submission['rating_num'].apply(lambda x: 0 if x<0 else x)\n",
    "submission.to_csv('my_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to Make a Submission?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"700\" height=\"380\" src=\"https://www.youtube.com/embed/zevnI9TgTtA\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML('<iframe width=\"700\" height=\"380\" src=\"https://www.youtube.com/embed/zevnI9TgTtA\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>')    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
