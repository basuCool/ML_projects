{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def customize_filters(stemming):\n",
    "    if(stemming==True):\n",
    "        filters = [lambda x: x.lower(),strip_punctuation,remove_stopwords,strip_multiple_whitespaces,stem_text]\n",
    "    else:\n",
    "        filters = [lambda x: x.lower(),strip_punctuation,remove_stopwords,strip_multiple_whitespaces]\n",
    "    return filters\n",
    "\n",
    "def read_db(db_type):\n",
    "    if(db_type==0):\n",
    "        db = pd.read_csv(CSV_PATH_DB )\n",
    "    if(db_type==1):\n",
    "        db = pd.read_excel(XLSX_PATH_DB)\n",
    "    if(db_type==2):\n",
    "        conn = pymssql.connect(host=MS_SQL_PATH_DB, user=MS_SQL_USER_DB,password=MS_SQL_PASSWORD_DB)\n",
    "        db = pd.read_sql(MS_SQL_DB_COLUMNS_QUERY,conn)\n",
    "    if(db_type==3):\n",
    "        conn = pymysql.connect(host=MY_SQL_PATH_DB, user=MY_SQL_USER_DB,password=MY_SQL_PASSWORD_DB,charset='utf8')\n",
    "        db = pd.read_sql(MY_SQL_DB_COLUMNS_QUERY,conn)\n",
    "    if(db_type == 4):\n",
    "        conn = pyhdb.connect(host = DB_HOST,port = DB_PORT,user = DB_USER,password = DB_PASSWORD)\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(SAP_HANA_DB_COLUMNS_QUERY)\n",
    "        data = cursor.fetchall()\n",
    "        connection.close()\n",
    "        db = pd.DataFrame(data)   \n",
    "    return db\n",
    "\n",
    "def read_dict(dict_type):\n",
    "    if(dict_type==0):\n",
    "        db = pd.read_csv(CSV_PATH_DICT )\n",
    "    if(dict_type==1):\n",
    "        db = pd.read_excel(XLSX_PATH_DICT)\n",
    "    if(dict_type==2):\n",
    "        conn = pymssql.connect(host=MS_SQL_PATH_DICT, user=MS_SQL_USER_DICT,password=MS_SQL_PASSWORD_DICT)\n",
    "        db = pd.read_sql(MS_SQL_DICT_COLUMNS_QUERY,conn)\n",
    "    if(dict_type==3):\n",
    "        conn = pymysql.connect(host=MY_SQL_PATH_DICT, user=MY_SQL_USER_DICT,password=MY_SQL_PASSWORD_DICT,charset='utf8')\n",
    "        db = pd.read_sql(MY_SQL_DICT_COLUMNS_QUERY,conn)\n",
    "    if(dict_type == 4):\n",
    "        conn = pyhdb.connect(host = DICT_HOST,port = DICT_PORT,user = DICT_USER,password = DICT_PASSWORD)\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(SAP_HANA_DICT_COLUMNS_QUERY)\n",
    "        data = cursor.fetchall()\n",
    "        connection.close()\n",
    "        db = pd.DataFrame(data)   \n",
    "    return db\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Gensim model\"\"\"\n",
    "import gensim\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "from gensim.parsing.preprocessing import preprocess_string\n",
    "from gensim.parsing.preprocessing import strip_tags\n",
    "from gensim.parsing.preprocessing import strip_punctuation\n",
    "from gensim.parsing.preprocessing import strip_multiple_whitespaces\n",
    "from gensim.parsing.preprocessing import stem_text\n",
    "\n",
    "\"\"\"NLTK natural language processing\"\"\"\n",
    "import nltk\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "import pymssql\n",
    "import re\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from autocorrect import spell\n",
    "import pprint\n",
    "import pyhdb\n",
    "\n",
    "\"\"\"set some defaults when displaying tables\"\"\"\n",
    "pd.set_option('display.max_rows',50)\n",
    "pd.set_option('display.max_columns',50)\n",
    "\n",
    "from IPython.core.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def customize_filters(stemming):\n",
    "    if(stemming==True):\n",
    "        filters = [lambda x: x.lower(),strip_punctuation,remove_stopwords,strip_multiple_whitespaces,stem_text]\n",
    "    else:\n",
    "        filters = [lambda x: x.lower(),strip_punctuation,remove_stopwords,strip_multiple_whitespaces]\n",
    "    return filters\n",
    "\n",
    "def read_db(db_type):\n",
    "    if(db_type==0):\n",
    "        db = pd.read_csv(CSV_PATH_DB )\n",
    "    if(db_type==1):\n",
    "        db = pd.read_excel(XLSX_PATH_DB)\n",
    "    if(db_type==2):\n",
    "        conn = pymssql.connect(server=SQL_PATH_DB, user=SQL_USER_DB,password=SQL_PASSWORD_DB)\n",
    "        db = pd.read_sql(SQL_DB_COLUMNS_QUERY,conn)\n",
    "    if(db_type == 3):\n",
    "        conn = pyhdb.connect(host = DB_HOST,port = DB_PORT,user = DB_USER,password = DB_PASSWORD)\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(SAP_HANA_DB_COLUMNS_QUERY)\n",
    "        data = cursor.fetchall()\n",
    "        connection.close()\n",
    "        db = pd.DataFrame(data)   \n",
    "    return db\n",
    "\n",
    "def read_dict(dict_type):\n",
    "    if(dict_type==0):\n",
    "        db = pd.read_csv(CSV_PATH_DICT )\n",
    "    if(dict_type==1):\n",
    "        db = pd.read_excel(XLSX_PATH_DICT)\n",
    "    if(dict_type==2):\n",
    "        conn = pymssql.connect(server=SQL_PATH_DICT, user=SQL_USER_DICT,password=SQL_PASSWORD_DICT)\n",
    "        db = pd.read_sql(SQL_DICT_COLUMNS_QUERY,conn)\n",
    "    if(dict_type == 3):\n",
    "        conn = pyhdb.connect(host = DICT_HOST,port = DICT_PORT,user = DICT_USER,password = DICT_PASSWORD)\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(SAP_HANA_DICT_COLUMNS_QUERY)\n",
    "        data = cursor.fetchall()\n",
    "        connection.close()\n",
    "        db = pd.DataFrame(data)   \n",
    "    return db\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUSTOM_FILTERS=customize_filters(STEMMED_WORDS)\n",
    "\n",
    "db = read_db(DB_TYPE)\n",
    "db = db.fillna('')\n",
    "\n",
    "db.columns = DB_COLS\n",
    "db['semantic']=db.loc[:,DB_COLS].apply(lambda x: ' '.join(map(str,x)), axis=1)\n",
    "\n",
    "db_subgrouped = db.set_index(DB_SUBGROUP_COLS)\n",
    "db_subgrouped = db_subgrouped.sort_index()\n",
    "        \n",
    "if(TECH_WORDS==1):\n",
    "    tech_db_dict = dict()\n",
    "    if(REGEX_TECHNICAL_WORDS == 0):\n",
    "        tech_db = read_dict(DICT_TYPE)\n",
    "        tech_db.columns = TECH_DICT_COLS\n",
    "        tech_db_dict = dict(zip(tech_db[TECH_DICT_TERM_COL],tech_db[TECH_DICT_DEFN_COL]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing functions\n",
    "\n",
    "LANGUAGE='english'\n",
    "\n",
    "\"\"\"import stopwords (is, has, would, etc) which act as misleading noise\"\"\"\n",
    "STOPWORDS_NLTK_EN=set(stopwords.words(LANGUAGE))\n",
    "STOPWORDS_PUNCT=set(punctuation)\n",
    "STOPWORDS_EN_WITHPUNCT=set.union(STOPWORDS_NLTK_EN,STOPWORDS_PUNCT)\n",
    "\n",
    "def get_dict(word_list):\n",
    "    word_dict=dict()\n",
    "    for word in word_list:\n",
    "        word_dict.setdefault(word,[word])\n",
    "    return word_dict\n",
    "\n",
    "def get_words(text):\n",
    "    return list(word_tokenize(text))\n",
    "        \n",
    "def get_autocorrected(word_list):\n",
    "    if(AUTOCORRECT_ON==True):\n",
    "        for i in range(len(word_list)):\n",
    "            word=word_list[i]\n",
    "            if word not in tech_dict.keys():\n",
    "                word_list[i]=spell(word)\n",
    "    return word_list\n",
    "        \n",
    "def populate_dictionary(dictionary):\n",
    "    for k,v in dictionary.items():\n",
    "        for syn in wordnet.synsets(k):\n",
    "            for l in syn.lemmas():\n",
    "                v.append(l.name())\n",
    "    return dictionary\n",
    "\n",
    "def preprocess_word_list(word_list):\n",
    "    sentence=' '.join(word_list)\n",
    "    return preprocess_string(sentence, CUSTOM_FILTERS)\n",
    "\n",
    "\n",
    "def get_non_technical_word_list(word_list):\n",
    "    non_tech_word_list=list([word for word in word_list if word not in technical_words.keys()])\n",
    "    return non_tech_word_list\n",
    "\n",
    "def get_db_technical_dict():\n",
    "    tech_dict=dict()\n",
    "    for k,v in tech_db_dict.items():\n",
    "        tech_dict.setdefault(str(k).lower(),v)\n",
    "    return tech_dict\n",
    "\n",
    "def get_regex_technical_dict():\n",
    "    text=db.loc[:,'semantic'].str.cat(sep=' ')\n",
    "    tech_list=list(set(re.findall(TECH_WORDS_REGEX,text)))\n",
    "    tech_dict=get_dict(tech_list)\n",
    "    return tech_dict\n",
    "\n",
    "def get_technical_word_dict():\n",
    "    tech_dict=dict()\n",
    "    if(TECH_WORDS==True):\n",
    "        tech_dict=dict()\n",
    "        if(REGEX_TECHNICAL_WORDS == True):\n",
    "            tech_dict = get_regex_technical_word_list()\n",
    "        else:\n",
    "            tech_dict = get_db_technical_dict()        \n",
    "    return tech_dict\n",
    "\n",
    "def preprocess_text(sentence):\n",
    "    word_list=get_words(sentence)\n",
    "    word_list=get_autocorrected(word_list)\n",
    "    sentence=' '.join(word_list)\n",
    "    return preprocess_string(sentence, CUSTOM_FILTERS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(TECH_WORDS==1):\n",
    "    technical_words=get_technical_word_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_sentences=db.loc[:,'semantic'].str.cat(sep=' ')\n",
    "words=get_words(row_sentences)\n",
    "\n",
    "non_technical_words=get_non_technical_word_list(words)\n",
    "non_technical_words=get_autocorrected(non_technical_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_tech=preprocess_word_list(non_technical_words)\n",
    "non_tech=get_dict(non_tech)\n",
    "\n",
    "non_tech_dict=populate_dictionary(non_tech)            \n",
    "non_tech_dict.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(PATH_NON_TECH_DICT,\"wb\")\n",
    "pickle.dump(non_tech_dict,f)\n",
    "f.close()\n",
    "\n",
    "f = open(PATH_TECH_DICT,\"wb\")\n",
    "pickle.dump(technical_words,f)\n",
    "f.close()\n",
    "\n",
    "f = open(PATH_DB_SUBGROUPED,\"wb\")\n",
    "pickle.dump(db_subgrouped,f)\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
